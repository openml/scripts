{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.llm import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config_and_device(\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"type_of_data\"] = \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Download the data if it does not exist\n",
    "openml_data_object, data_id, all_dataset_metadata = get_all_metadata_from_openml(\n",
    "        config=config\n",
    "    )\n",
    "# Create the combined metadata dataframe\n",
    "metadata_df, all_dataset_metadata = create_metadata_dataframe(\n",
    "        openml_data_object, data_id, all_dataset_metadata, config=config\n",
    "    )\n",
    "\n",
    "# Create the vector database using Chroma db with each type of data in its own collection. Doing so allows us to have a single database with multiple collections, reducing the number of databases we need to manage.\n",
    "# This also downloads the embedding model if it does not exist\n",
    "vectordb = load_document_and_create_vector_store(metadata_df, config=config)\n",
    "\n",
    "# Setup llm chain, initialize the retriever and llm, and setup Retrieval QA\n",
    "qa = initialize_llm_chain(vectordb=vectordb, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>page_content</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18090</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18090, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18431</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18431, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18401</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18401, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18433</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18433, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18229</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18229, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               name  \\\n",
       "0  18090  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "1  18431  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "2  18401  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "3  18433  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "4  18229  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "\n",
       "                                        page_content  \\\n",
       "0  id - 18090, full_name - sklearn.pipeline.Pipel...   \n",
       "1  id - 18431, full_name - sklearn.pipeline.Pipel...   \n",
       "2  id - 18401, full_name - sklearn.pipeline.Pipel...   \n",
       "3  id - 18433, full_name - sklearn.pipeline.Pipel...   \n",
       "4  id - 18229, full_name - sklearn.pipeline.Pipel...   \n",
       "\n",
       "                                            urls  \n",
       "0  https://www.openml.org/api/v1/json/flow/18090  \n",
       "1  https://www.openml.org/api/v1/json/flow/18431  \n",
       "2  https://www.openml.org/api/v1/json/flow/18401  \n",
       "3  https://www.openml.org/api/v1/json/flow/18433  \n",
       "4  https://www.openml.org/api/v1/json/flow/18229  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time\n",
    "# query = \"Which datasets would be useful for stock market support?\"\n",
    "# query = \"Which datasets would be useful for heart disease\"\n",
    "# query = \"Which datasets would be useful for flowers\"\n",
    "# query = \"Which datasets would be useful for image classification\"\n",
    "# query = \"My supervisor wants me to work on cloud cover, which datasets can I use\"\n",
    "# query = \"Are there any datasets from the netherlands?\"\n",
    "# query = \"Are there any datasets about farm animals?\"\n",
    "# query = \"Find chinese authors\"\n",
    "query = \"Which flow can I use for classifying categories of data efficiently\"\n",
    "result_data_frame = get_result_from_query(\n",
    "        query=query, qa=qa, config=config\n",
    "    )\n",
    "result_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id - 18090, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectPercentile,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectPercentile,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18431, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18401, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.naive_bayes.BernoulliNB)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.naive_bayes.BernoulliNB), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18433, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18229, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._data.MinMaxScaler,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._data.MinMaxScaler,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18440, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.ensemble._weight_boosting.AdaBoostClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.ensemble._weight_boosting.AdaBoostClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18112, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.cluster._agglomerative.FeatureAgglomeration,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.cluster._agglomerative.FeatureAgglomeration,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 20050, full_name - sklearn.pipeline.Pipeline(columntransformer=sklearn.compose._column_transformer.ColumnTransformer(simpleimputer=sklearn.impute._base.SimpleImputer,onehotencoder=sklearn.preprocessing._encoders.OneHotEncoder),decisiontreeclassifier=sklearn.tree._classes.DecisionTreeClassifier)(9), name - sklearn.pipeline.Pipeline(columntransformer=sklearn.compose._column_transformer.ColumnTransformer(simpleimputer=sklearn.impute._base.SimpleImputer,onehotencoder=sklearn.preprocessing._encoders.OneHotEncoder),decisiontreeclassifier=sklearn.tree._classes.DecisionTreeClassifier), version - 9, external_version - openml==0.14.2,sklearn==1.3.2, uploader - 37571,',\n",
       "       'id - 18130, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._discretization.KBinsDiscretizer,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._discretization.KBinsDiscretizer,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18100, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.decomposition._factor_analysis.FactorAnalysis,step_2=sklearn.linear_model._stochastic_gradient.SGDClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.decomposition._factor_analysis.FactorAnalysis,step_2=sklearn.linear_model._stochastic_gradient.SGDClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data_frame['page_content'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.openml.org/api/v1/json/flow/18090',\n",
       "       'https://www.openml.org/api/v1/json/flow/18431',\n",
       "       'https://www.openml.org/api/v1/json/flow/18401',\n",
       "       'https://www.openml.org/api/v1/json/flow/18433',\n",
       "       'https://www.openml.org/api/v1/json/flow/18229',\n",
       "       'https://www.openml.org/api/v1/json/flow/18440',\n",
       "       'https://www.openml.org/api/v1/json/flow/18112',\n",
       "       'https://www.openml.org/api/v1/json/flow/20050',\n",
       "       'https://www.openml.org/api/v1/json/flow/18130',\n",
       "       'https://www.openml.org/api/v1/json/flow/18100'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data_frame['urls'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectPercentile,step_2=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.naive_bayes.BernoulliNB)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._data.MinMaxScaler,step_2=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.ensemble._weight_boosting.AdaBoostClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.cluster._agglomerative.FeatureAgglomeration,step_2=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(columntransformer=sklearn.compose._column_transformer.ColumnTransformer(simpleimputer=sklearn.impute._base.SimpleImputer,onehotencoder=sklearn.preprocessing._encoders.OneHotEncoder),decisiontreeclassifier=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._discretization.KBinsDiscretizer,step_2=sklearn.tree._classes.DecisionTreeClassifier)',\n",
       "       'sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.decomposition._factor_analysis.FactorAnalysis,step_2=sklearn.linear_model._stochastic_gradient.SGDClassifier)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data_frame['name'].values[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
