{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tempfile\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# from langchain.llms import VertexAI\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.document_loaders import (\n",
    "    DirectoryLoader,\n",
    "    PyPDFLoader,\n",
    "    PyPDFDirectoryLoader,\n",
    "    DirectoryLoader,\n",
    ")\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    TextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import ChatMessageHistory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pqdm.threads import pqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_KEY = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# use export HUGGINGFACEHUB_API_TOKEN=your_token_here to set the token (in the shell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_description(dataset_name) -> openml.datasets.dataset.OpenMLDataset:\n",
    "    try:\n",
    "        data = openml.datasets.get_dataset(dataset_name, download_data = False, download_qualities = False, download_features_meta_data = False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataset_metadata_from_openml(save_filename = \"all_dataset_metadata.pkl\") -> Union[List, List]:\n",
    "    # Gather all OpenML datasets\n",
    "    all_datasets = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "\n",
    "    # List dataset 'did' to be used as an identifier \n",
    "    data_id = [all_datasets.iloc[i]['did'] for i in range(len(all_datasets))]\n",
    "\n",
    "    dataset_names = all_datasets['name'].tolist() # get a list of all dataset names\n",
    "\n",
    "    # if the file already exists, load it else get the metadata from openml\n",
    "    if os.path.exists(save_filename):\n",
    "        with open(save_filename, 'rb') as f:\n",
    "            all_data_descriptions = pickle.load(f)\n",
    "        return all_data_descriptions, data_id\n",
    "    else:\n",
    "        # Get all dataset metadata using n_jobs parallel threads from openml\n",
    "        all_data_descriptions = pqdm(dataset_names, get_dataset_description, n_jobs=10)\n",
    "\n",
    "        # Save the metadata to a file\n",
    "        with open(save_filename, 'wb') as f:\n",
    "            pickle.dump(all_data_descriptions, f)\n",
    "        \n",
    "        return all_data_descriptions, data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_dataframe(all_data_descriptions, data_id) -> pd.DataFrame:\n",
    "    descriptions = [all_data_descriptions[i].description for i in range(len(all_data_descriptions))]\n",
    "\n",
    "    all_data_description = dict(zip(data_id, descriptions))\n",
    "\n",
    "    return pd.DataFrame(list(all_data_description.items()),columns = ['did','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_metadata_dataframe(metadata_df) -> pd.DataFrame:\n",
    "    # remove rows with empty descriptions\n",
    "    metadata_df = metadata_df[metadata_df['description'].notna()]\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = create_metadata_dataframe(*get_all_dataset_metadata_from_openml())\n",
    "metadata_df = clean_metadata_dataframe(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Mary McLeish & Matt Cecile, University of Guelph  \n",
      "Donor: Will Taylor (taylor@pluto.arc.nasa.gov)   \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Horse+Colic) - 8/6/89   \n",
      "\n",
      "**Horse Colic database**  \n",
      "Database of surgeries on horses. Possible class attributes: 24 (whether lesion is surgical), others include: 23, 25, 26, and 27\n",
      "\n",
      "Notes:\n",
      "* Hospital_Number is an identifier and should be ignored when modelling\n",
      "\n",
      "Attribute Information:\n",
      "> \n",
      "   1:  surgery?\n",
      "           1 = Yes, it had surgery\n",
      "           2 = It was treated without surgery  \n",
      "   2:  Age \n",
      "           1 = Adult horse\n",
      "           2 = Young (< 6 months)  \n",
      "   3:  Hospital Number \n",
      "           - numeric id\n",
      "           - the case number assigned to the horse\n",
      "             (may not be unique if the horse is treated > 1 time)  \n",
      "   4:  rectal temperature\n",
      "           - linear\n",
      "           - in degrees celsius.\n",
      "           - An elevated temp may occur due to infection.\n",
      "           - temperature may be reduced when the animal is in late shock\n",
      "           - normal temp is 37.8\n",
      "           - this parameter will usually change as the problem progresses\n",
      "                eg. may start out normal, then become elevated because of\n",
      "                    the lesion, passing back through the normal range as the\n",
      "                    horse goes into shock  \n",
      "   5:  pulse \n",
      "           - linear\n",
      "           - the heart rate in beats per minute\n",
      "           - is a reflection of the heart condition: 30 -40 is normal for adults\n",
      "           - rare to have a lower than normal rate although athletic horses\n",
      "             may have a rate of 20-25\n",
      "           - animals with painful lesions or suffering from circulatory shock\n",
      "             may have an elevated heart rate  \n",
      "   6:  respiratory rate\n",
      "           - linear\n",
      "           - normal rate is 8 to 10\n",
      "           - usefulness is doubtful due to the great fluctuations  \n",
      "   7:  temperature of extremities\n",
      "           - a subjective indication of peripheral circulation\n",
      "           - possible values:\n",
      "                1 = Normal\n",
      "                2 = Warm\n",
      "                3 = Cool\n",
      "                4 = Cold\n",
      "           - cool to cold extremities indicate possible shock\n",
      "           - hot extremities should correlate with an elevated rectal temp.  \n",
      "   8:  peripheral pulse\n",
      "           - subjective\n",
      "           - possible values are:\n",
      "                1 = normal\n",
      "                2 = increased\n",
      "                3 = reduced\n",
      "                4 = absent\n",
      "           - normal or increased p.p. are indicative of adequate circulation\n",
      "             while reduced or absent indicate poor perfusion  \n",
      "   9:  mucous membranes\n",
      "           - a subjective measurement of colour\n",
      "           - possible values are:\n",
      "                1 = normal pink\n",
      "                2 = bright pink\n",
      "                3 = pale pink\n",
      "                4 = pale cyanotic\n",
      "                5 = bright red / injected\n",
      "                6 = dark cyanotic\n",
      "           - 1 and 2 probably indicate a normal or slightly increased\n",
      "             circulation\n",
      "           - 3 may occur in early shock\n",
      "           - 4 and 6 are indicative of serious circulatory compromise\n",
      "           - 5 is more indicative of a septicemia  \n",
      "  10: capillary refill time\n",
      "           - a clinical judgement. The longer the refill, the poorer the\n",
      "             circulation\n",
      "           - possible values\n",
      "                1 = < 3 seconds\n",
      "                2 = >= 3 seconds  \n",
      "  11: pain - a subjective judgement of the horse's pain level\n",
      "           - possible values:\n",
      "                1 = alert, no pain\n",
      "                2 = depressed\n",
      "                3 = intermittent mild pain\n",
      "                4 = intermittent severe pain\n",
      "                5 = continuous severe pain\n",
      "           - should NOT be treated as a ordered or discrete variable!\n",
      "           - In general, the more painful, the more likely it is to require\n",
      "             surgery\n",
      "           - prior treatment of pain may mask the pain level to some extent  \n",
      "  12: peristalsis                              \n",
      "           - an indication of the activity in the horse's gut. As the gut\n",
      "             becomes more distended or the horse becomes more toxic, the\n",
      "             activity decreases\n",
      "           - possible values:\n",
      "                1 = hypermotile\n",
      "                2 = normal\n",
      "                3 = hypomotile\n",
      "                4 = absent  \n",
      "  13: abdominal distension\n",
      "           - An IMPORTANT parameter.\n",
      "           - possible values\n",
      "                1 = none\n",
      "                2 = slight\n",
      "                3 = moderate\n",
      "                4 = severe\n",
      "           - an animal with abdominal distension is likely to be painful and\n",
      "             have reduced gut motility.\n",
      "           - a horse with severe abdominal distension is likely to require\n",
      "             surgery just tio relieve the pressure  \n",
      "  14: nasogastric tube\n",
      "           - this refers to any gas coming out of the tube\n",
      "           - possible values:\n",
      "                1 = none\n",
      "                2 = slight\n",
      "                3 = significant\n",
      "           - a large gas cap in the stomach is likely to give the horse\n",
      "             discomfort  \n",
      "  15: nasogastric reflux\n",
      "           - possible values\n",
      "                1 = none\n",
      "                2 = > 1 liter\n",
      "                3 = < 1 liter\n",
      "           - the greater amount of reflux, the more likelihood that there is\n",
      "             some serious obstruction to the fluid passage from the rest of\n",
      "             the intestine  \n",
      "  16: nasogastric reflux PH\n",
      "           - linear\n",
      "           - scale is from 0 to 14 with 7 being neutral\n",
      "           - normal values are in the 3 to 4 range  \n",
      "  17: rectal examination - feces\n",
      "           - possible values\n",
      "                1 = normal\n",
      "                2 = increased\n",
      "                3 = decreased\n",
      "                4 = absent\n",
      "           - absent feces probably indicates an obstruction  \n",
      "  18: abdomen\n",
      "           - possible values\n",
      "                1 = normal\n",
      "                2 = other\n",
      "                3 = firm feces in the large intestine\n",
      "                4 = distended small intestine\n",
      "                5 = distended large intestine\n",
      "           - 3 is probably an obstruction caused by a mechanical impaction\n",
      "             and is normally treated medically\n",
      "           - 4 and 5 indicate a surgical lesion  \n",
      "  19: packed cell volume\n",
      "           - linear\n",
      "           - the # of red cells by volume in the blood\n",
      "           - normal range is 30 to 50. The level rises as the circulation\n",
      "             becomes compromised or as the animal becomes dehydrated.  \n",
      "  20: total protein\n",
      "           - linear\n",
      "           - normal values lie in the 6-7.5 (gms/dL) range\n",
      "           - the higher the value the greater the dehydration  \n",
      "  21: abdominocentesis appearance\n",
      "           - a needle is put in the horse's abdomen and fluid is obtained from\n",
      "             the abdominal cavity\n",
      "           - possible values:\n",
      "                1 = clear\n",
      "                2 = cloudy\n",
      "                3 = serosanguinous\n",
      "           - normal fluid is clear while cloudy or serosanguinous indicates\n",
      "             a compromised gut  \n",
      "  22: abdomcentesis total protein\n",
      "           - linear\n",
      "           - the higher the level of protein the more likely it is to have a\n",
      "             compromised gut. Values are in gms/dL  \n",
      "  23: outcome\n",
      "           - what eventually happened to the horse?\n",
      "           - possible values:\n",
      "                1 = lived\n",
      "                2 = died\n",
      "                3 = was euthanized  \n",
      "  24: surgical lesion?\n",
      "           - retrospectively, was the problem (lesion) surgical?\n",
      "           - all cases are either operated upon or autopsied so that\n",
      "             this value and the lesion type are always known\n",
      "           - possible values:\n",
      "                1 = Yes\n",
      "                2 = No  \n",
      "  25, 26, 27: type of lesion\n",
      "           - first number is site of lesion\n",
      "                1 = gastric\n",
      "                2 = sm intestine\n",
      "                3 = lg colon\n",
      "                4 = lg colon and cecum\n",
      "                5 = cecum\n",
      "                6 = transverse colon\n",
      "                7 = retum/descending colon\n",
      "                8 = uterus\n",
      "                9 = bladder\n",
      "                11 = all intestinal sites\n",
      "                00 = none\n",
      "           - second number is type\n",
      "                1 = simple\n",
      "                2 = strangulation\n",
      "                3 = inflammation\n",
      "                4 = other\n",
      "           - third number is subtype\n",
      "                1 = mechanical\n",
      "                2 = paralytic\n",
      "                0 = n/a\n",
      "           - fourth number is specific code\n",
      "                1 = obturation\n",
      "                2 = intrinsic\n",
      "                3 = extrinsic\n",
      "                4 = adynamic\n",
      "                5 = volvulus/torsion\n",
      "                6 = intussuption\n",
      "                7 = thromboembolic\n",
      "                8 = hernia\n",
      "                9 = lipoma/slenic incarceration\n",
      "                10 = displacement\n",
      "                0 = n/a\n",
      "  28: cp_data\n",
      "           - is pathology data present for this case?\n",
      "                1 = Yes\n",
      "                2 = No\n",
      "           - this variable is of no significance since pathology data\n",
      "             is not included or collected for these cases\n"
     ]
    }
   ],
   "source": [
    "print(metadata_df.loc[20]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import langchain_core\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_and_retriever(chunked_docs, model_name = \"BAAI/bge-base-en-v1.5\"):\n",
    "    db = FAISS.from_documents(chunked_docs, HuggingFaceEmbeddings(model_name=model_name))\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "    return db, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_add_to_chroma_db(documents, embeddings, persist_directory = \"./chroma_db/\") -> Chroma:\n",
    "    # https://github.com/zylon-ai/private-gpt/issues/257#issuecomment-1666622098\n",
    "    if len(documents) > 100:\n",
    "        batch_size = int(len(documents) / 100)\n",
    "        batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "        for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "            db = Chroma.from_documents(\n",
    "                batch, embedding=embeddings, persist_directory=persist_directory)\n",
    "    else:\n",
    "        db = Chroma.from_documents(\n",
    "        documents, embedding=embeddings, persist_directory=persist_directory)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document_and_create_vector_store(metadata_df, persist_directory = \"./chroma_db/\", model_name = \"BAAI/bge-base-en-v1.5\", device = \"cpu\", normalize_embeddings = True, recreate_chroma = False) -> Chroma:\n",
    "    # if the directory already exists, load the vector store else create a new one\n",
    "    if os.path.exists(persist_directory) and not recreate_chroma:\n",
    "        db = Chroma.load(persist_directory)\n",
    "        return db\n",
    "    else:\n",
    "        # load data\n",
    "        # might need to chunk if the descriptions are too large, fine for now\n",
    "        loader = DataFrameLoader(metadata_df, page_content_column=\"description\")\n",
    "        documents = loader.load() \n",
    "\n",
    "        # load model\n",
    "        model_kwargs = {\"device\": device}\n",
    "        encode_kwargs = {\"normalize_embeddings\": normalize_embeddings}\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "        )\n",
    "\n",
    "        # create vector store in batches\n",
    "        return parallel_add_to_chroma_db(documents, embeddings, persist_directory=persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eragon/.pyenv/versions/3.9.19/envs/openml/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing batches:  48%|████▊     | 48/101 [06:20<07:40,  8.69s/it]"
     ]
    }
   ],
   "source": [
    "vectordb = load_document_and_create_vector_store(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever_and_llm(model_name = \"HuggingFaceH4/zephyr-7b-beta\", num_return_documents = 10,search_type = \"similarity\"):\n",
    "    retriever = vectordb.as_retriever(search_type=search_type, search_kwargs={\"k\": num_return_documents})\n",
    "    llm = HuggingFaceHub(model_name=model_name,model_kwargs={\"temperature\": 0.1, \"max_length\": 512}, api_key=HUGGINGFACEHUB_API_KEY)\n",
    "    return retriever, llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eragon/.pyenv/versions/3.9.19/envs/openml/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(df, page_content_column=\"description\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "        documents, embedding=embeddings, persist_directory=\"./testdir\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Initiate llm generator. Temperature = 0 (Not creative). Temperature = 1 (Creative). Using\n",
    "llm = HuggingFaceHub(\n",
    "    # repo_id=\"declare-lab/flan-alpaca-large\",\n",
    "    # repo_id = \"google/flan-t5-large\",\n",
    "    repo_id = \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    # repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_length\": 512},\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqa_prompt_template = \"This database is a list of dataset metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RQA_PROMPT = PromptTemplate(\n",
    "    template=rqa_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "rqa_chain_type_kwargs = {\"prompt\": RQA_PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    # chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=rqa_chain_type_kwargs,\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Find me documents that talk about diseases\"\n",
    "query = \"Which datasets are good for finance problems\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which datasets are good for finance problems',\n",
       " 'result': 'This database is a list of dataset metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the Which datasets are good for finance problems given. If you do not know the answer, say you do not know. **Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)\\n\\n**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)\\n\\n**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)\\n\\n**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)\\n\\n**Author**: Confidential - Donated by Ross Quinlan   \\n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/credit+approval) - 1987  \\n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \\n\\n**Credit Approval**\\nThis file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.  \\n   \\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.\\n\\n### Attribute description  \\n\\n1. Credit history (number of times line was delinquent)\\n2. Present employment since registration month (number of months)\\n3. Monthly income (in dollars)\\n4. Number of existing credits (this count includes the credit being applied for)\\n5. The statement balance (in dollars)\\n6. Amount of credit requested (in dollars)\\n7. The repayment rate (this is the proportion of the',\n",
       " 'source_documents': [Document(page_content='**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)', metadata={'did': 31}),\n",
       "  Document(page_content='**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)', metadata={'did': 31}),\n",
       "  Document(page_content='**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)', metadata={'did': 31}),\n",
       "  Document(page_content='**Author**: Dr. Hans Hofmann  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\\n\\n**German Credit dataset**  \\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\\n\\nThis dataset comes with a cost matrix: \\n``` \\nGood  Bad (predicted)  \\nGood   0    1   (actual)  \\nBad    5    0  \\n```\\n\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \\n\\n### Attribute description  \\n\\n1. Status of existing checking account, in Deutsche Mark.  \\n2. Duration in months  \\n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \\n4. Purpose of the credit (car, television,...)  \\n5. Credit amount  \\n6. Status of savings account/bonds, in Deutsche Mark.  \\n7. Present employment, in number of years.  \\n8. Installment rate in percentage of disposable income  \\n9. Personal status (married, single,...) and sex  \\n10. Other debtors / guarantors  \\n11. Present residence since X years  \\n12. Property (e.g. real estate)  \\n13. Age in years  \\n14. Other installment plans (banks, stores)  \\n15. Housing (rent, own,...)  \\n16. Number of existing credits at this bank  \\n17. Job  \\n18. Number of people being liable to provide maintenance for  \\n19. Telephone (yes,no)  \\n20. Foreign worker (yes,no)', metadata={'did': 31}),\n",
       "  Document(page_content='**Author**: Confidential - Donated by Ross Quinlan   \\n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/credit+approval) - 1987  \\n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \\n\\n**Credit Approval**\\nThis file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.  \\n   \\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.', metadata={'did': 29})]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 31, 31, 31, 29]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs = [doc.metadata['did'] for doc in result[\"source_documents\"]]\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    **Author**: Confidential - Donated by Ross Qui...\n",
       "26    **Author**: Dr. Hans Hofmann  \\n**Source**: [U...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get description of the relevant documents using df\n",
    "test_descrptions = df[df['did'].isin(relevant_docs)][\"description\"]\n",
    "test_descrptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Confidential - Donated by Ross Quinlan   \n",
      "**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/credit+approval) - 1987  \n",
      "**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \n",
      "\n",
      "**Credit Approval**\n",
      "This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.  \n",
      "   \n",
      "This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.\n"
     ]
    }
   ],
   "source": [
    "print(test_descrptions.to_list()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
