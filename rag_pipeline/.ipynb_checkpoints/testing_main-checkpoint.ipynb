{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.llm import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"rqa_prompt_template\" : \"This database is a list of dataset metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}\",\n",
    "    \"num_return_documents\" : 50,\n",
    "    \"embedding_model\": \"BAAI/bge-base-en-v1.5\",\n",
    "    # \"embedding_model\": \"Intel/bge-small-en-v1.5-rag-int8-static\",\n",
    "    \"llm_model\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    \"persist_dir\": \"./chroma_db/\",\n",
    "    # \"recreate_chroma\": False,\n",
    "    \"recreate_chroma\": True,\n",
    "    \"recreate_data_cache\" : False,\n",
    "    # \"recreate_data_cache\" : True,\n",
    "    \"data_download_n_jobs\" : 30,\n",
    "    \"device\" : \"cuda\", # Change to \"cuda\" if you have a GPU or \"cpu\" if you don't. MPS is for Mac M{1..3} machines.\n",
    "    \"type_of_data\" : \"flow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_data_object, data_id, all_dataset_metadata = get_all_metadata_from_openml(recreate_cache=config[\"recreate_data_cache\"], type_of_data = config[\"type_of_data\"],n_jobs=config[\"data_download_n_jobs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df, all_dataset_metadata = create_metadata_dataframe(openml_data_object, data_id, all_dataset_metadata, type_of_data = config[\"type_of_data\"])\n",
    "metadata_df = clean_metadata_dataframe(metadata_df, type_of_data = config[\"type_of_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████| 111/111 [03:13<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "vectordb = load_document_and_create_vector_store(metadata_df, model_name=config['embedding_model'], recreate_chroma=config['recreate_chroma'], persist_directory=config['persist_dir'], device=config['device'], type_of_data = config[\"type_of_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "retriever, llm = create_retriever_and_llm(vectordb,num_return_documents=config[\"num_return_documents\"], model_repo_id=config[\"llm_model\"])\n",
    "qa = create_llm_chain_and_query(vectordb=vectordb,retriever=retriever,llm=llm, prompt_template = config[\"rqa_prompt_template\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dataframe(query, qa, all_dataset_metadata, type_of_data = \"runs\") -> pd.DataFrame:\n",
    "    if type_of_data == \"dataset\":\n",
    "        type_of_data = \"data\"\n",
    "        results = qa.invoke({\"query\": query})\n",
    "        dict_results = {}\n",
    "        for result in results[\"source_documents\"]:\n",
    "            dict_results[result.metadata[\"did\"]] = {\"name\": result.metadata[\"name\"] , \"page_content\" : result.page_content}\n",
    "    \n",
    "        output_df = pd.DataFrame(dict_results).T.reset_index() \n",
    "        output_df[\"urls\"] = output_df[\"index\"].apply(lambda x: f\"https://www.openml.org/api/v1/json/{type_of_data}/{x}\")\n",
    "        return output_df\n",
    "    elif type_of_data == \"flow\":\n",
    "        results = qa.invoke({\"query\": query})\n",
    "        dict_results = {}\n",
    "        for result in results[\"source_documents\"]:\n",
    "            dict_results[result.metadata[\"id\"]] = {\"name\": result.metadata[\"name\"] , \"page_content\" : result.page_content}\n",
    "    \n",
    "        output_df = pd.DataFrame(dict_results).T.reset_index() \n",
    "        output_df[\"urls\"] = output_df[\"index\"].apply(lambda x: f\"https://www.openml.org/api/v1/json/{type_of_data}/{x}\")\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>page_content</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18090</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18090, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18431</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18431, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18401</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18401, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18433</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18433, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18229</td>\n",
       "      <td>sklearn.pipeline.Pipeline(step_0=automl.compon...</td>\n",
       "      <td>id - 18229, full_name - sklearn.pipeline.Pipel...</td>\n",
       "      <td>https://www.openml.org/api/v1/json/flow/18229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               name  \\\n",
       "0  18090  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "1  18431  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "2  18401  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "3  18433  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "4  18229  sklearn.pipeline.Pipeline(step_0=automl.compon...   \n",
       "\n",
       "                                        page_content  \\\n",
       "0  id - 18090, full_name - sklearn.pipeline.Pipel...   \n",
       "1  id - 18431, full_name - sklearn.pipeline.Pipel...   \n",
       "2  id - 18401, full_name - sklearn.pipeline.Pipel...   \n",
       "3  id - 18433, full_name - sklearn.pipeline.Pipel...   \n",
       "4  id - 18229, full_name - sklearn.pipeline.Pipel...   \n",
       "\n",
       "                                            urls  \n",
       "0  https://www.openml.org/api/v1/json/flow/18090  \n",
       "1  https://www.openml.org/api/v1/json/flow/18431  \n",
       "2  https://www.openml.org/api/v1/json/flow/18401  \n",
       "3  https://www.openml.org/api/v1/json/flow/18433  \n",
       "4  https://www.openml.org/api/v1/json/flow/18229  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time\n",
    "# query = \"Which datasets would be useful for stock market support?\"\n",
    "# query = \"Which datasets would be useful for heart disease\"\n",
    "# query = \"Which datasets would be useful for flowers\"\n",
    "# query = \"Which datasets would be useful for image classification\"\n",
    "# query = \"My supervisor wants me to work on cloud cover, which datasets can I use\"\n",
    "# query = \"Are there any datasets from the netherlands?\"\n",
    "# query = \"Are there any datasets about farm animals?\"\n",
    "# query = \"Find chinese authors\"\n",
    "query = \"Which flow can I use for classifying categories of data efficiently\"\n",
    "results = create_result_dataframe(query, qa, all_dataset_metadata, type_of_data=\"flow\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id - 18090, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectPercentile,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectPercentile,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18431, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18401, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.naive_bayes.BernoulliNB)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.naive_bayes.BernoulliNB), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18433, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=automl.util.sklearn.StackingEstimator(estimator=sklearn.tree._classes.DecisionTreeClassifier),step_2=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18229, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._data.MinMaxScaler,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._data.MinMaxScaler,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18440, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.ensemble._weight_boosting.AdaBoostClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.feature_selection._univariate_selection.SelectKBest,step_2=sklearn.ensemble._weight_boosting.AdaBoostClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18112, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.cluster._agglomerative.FeatureAgglomeration,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.cluster._agglomerative.FeatureAgglomeration,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 20050, full_name - sklearn.pipeline.Pipeline(columntransformer=sklearn.compose._column_transformer.ColumnTransformer(simpleimputer=sklearn.impute._base.SimpleImputer,onehotencoder=sklearn.preprocessing._encoders.OneHotEncoder),decisiontreeclassifier=sklearn.tree._classes.DecisionTreeClassifier)(9), name - sklearn.pipeline.Pipeline(columntransformer=sklearn.compose._column_transformer.ColumnTransformer(simpleimputer=sklearn.impute._base.SimpleImputer,onehotencoder=sklearn.preprocessing._encoders.OneHotEncoder),decisiontreeclassifier=sklearn.tree._classes.DecisionTreeClassifier), version - 9, external_version - openml==0.14.2,sklearn==1.3.2, uploader - 37571,',\n",
       "       'id - 18130, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._discretization.KBinsDiscretizer,step_2=sklearn.tree._classes.DecisionTreeClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.preprocessing._discretization.KBinsDiscretizer,step_2=sklearn.tree._classes.DecisionTreeClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,',\n",
       "       'id - 18100, full_name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.decomposition._factor_analysis.FactorAnalysis,step_2=sklearn.linear_model._stochastic_gradient.SGDClassifier)(1), name - sklearn.pipeline.Pipeline(step_0=automl.components.feature_preprocessing.multi_column_label_encoder.MultiColumnLabelEncoderComponent,step_1=sklearn.decomposition._factor_analysis.FactorAnalysis,step_2=sklearn.linear_model._stochastic_gradient.SGDClassifier), version - 1, external_version - automl==0.0.1,openml==0.10.2,sklearn==0.22.1, uploader - 12269,'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['page_content'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.openml.org/api/v1/json/flow/8188',\n",
       "       'https://www.openml.org/api/v1/json/flow/8187',\n",
       "       'https://www.openml.org/api/v1/json/flow/8283',\n",
       "       'https://www.openml.org/api/v1/json/flow/9178',\n",
       "       'https://www.openml.org/api/v1/json/flow/8091',\n",
       "       'https://www.openml.org/api/v1/json/flow/18698',\n",
       "       'https://www.openml.org/api/v1/json/flow/7823',\n",
       "       'https://www.openml.org/api/v1/json/flow/8035',\n",
       "       'https://www.openml.org/api/v1/json/flow/5848',\n",
       "       'https://www.openml.org/api/v1/json/flow/18925'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['urls'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BTC', 'COVID-19-biotech-companies-on-stock-exchange(2020)',\n",
       "       'Apple-Historical-Dataset',\n",
       "       'Ethereum-Cryptocurrency-Historical-Dataset',\n",
       "       'Corporate-Credit-Rating', 'Stock-Information',\n",
       "       'Historical-data-on-the-trading-of-cryptocurrencies',\n",
       "       'Stock-price-trend-prediction', 'Stock-Market-NIFTY50-Index-Data',\n",
       "       'Google-Stock-10Year-data2004-2020'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['name'].values[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
