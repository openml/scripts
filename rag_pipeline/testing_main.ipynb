{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.llm import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"rqa_prompt_template\" : \"This database is a list of dataset metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}\",\n",
    "    \"num_return_documents\" : 100,\n",
    "    \"embedding_model\": \"BAAI/bge-base-en-v1.5\",\n",
    "    \"llm_model\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    \"recreate_chroma\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Mary McLeish & Matt Cecile, University of Guelph  \n",
      "Donor: Will Taylor (taylor@pluto.arc.nasa.gov)   \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Horse+Colic) - 8/6/89   \n",
      "\n",
      "**Horse Colic database**  \n",
      "Database of surgeries on horses. Possible class attributes: 24 (whether lesi\n"
     ]
    }
   ],
   "source": [
    "metadata_df = create_metadata_dataframe(*get_all_dataset_metadata_from_openml())\n",
    "metadata_df = clean_metadata_dataframe(metadata_df)\n",
    "\n",
    "print(metadata_df.loc[20]['description'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eragon/.pyenv/versions/3.9.19/envs/openml/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectordb = load_document_and_create_vector_store(metadata_df, model_name=config['embedding_model'], recreate_chroma=config['recreate_chroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eragon/.pyenv/versions/3.9.19/envs/openml/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "retriever, llm = create_retriever_and_llm(vectordb,num_return_documents=config[\"num_return_documents\"], model_repo_id=config[\"llm_model\"])\n",
    "qa = create_llm_chain_and_query(vectordb=vectordb,retriever=retriever,llm=llm, prompt_template = config[\"rqa_prompt_template\"])\n",
    "\n",
    "query = \"Which datasets would be useful for stock market information?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>description</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43006</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43004</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43003</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43005</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "      <td>This datasets covers features from various cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43555</td>\n",
       "      <td>Check the movement of the financial market thr...</td>\n",
       "      <td>Check the movement of the financial market thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>40981</td>\n",
       "      <td>**Author**: Confidential. Donated by Ross Quin...</td>\n",
       "      <td>**Author**: Confidential. Donated by Ross Quin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>664</td>\n",
       "      <td>More information about the data sets and the b...</td>\n",
       "      <td>More information about the data sets and the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1030</td>\n",
       "      <td>3. Past Usage:\\n\\n4. Relevant Information\\nThe...</td>\n",
       "      <td>3. Past Usage:\\n\\n4. Relevant Information\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>43545</td>\n",
       "      <td>Context\\nThis dataset was created when I pract...</td>\n",
       "      <td>Context\\nThis dataset was created when I pract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>42889</td>\n",
       "      <td>We scraped a large number of eBay auctions of ...</td>\n",
       "      <td>We scraped a large number of eBay auctions of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      did                                        description  \\\n",
       "0   43006  This datasets covers features from various cat...   \n",
       "1   43004  This datasets covers features from various cat...   \n",
       "2   43003  This datasets covers features from various cat...   \n",
       "3   43005  This datasets covers features from various cat...   \n",
       "4   43555  Check the movement of the financial market thr...   \n",
       "..    ...                                                ...   \n",
       "90  40981  **Author**: Confidential. Donated by Ross Quin...   \n",
       "91    664  More information about the data sets and the b...   \n",
       "92   1030  3. Past Usage:\\n\\n4. Relevant Information\\nThe...   \n",
       "93  43545  Context\\nThis dataset was created when I pract...   \n",
       "94  42889  We scraped a large number of eBay auctions of ...   \n",
       "\n",
       "                                    short_description  \n",
       "0   This datasets covers features from various cat...  \n",
       "1   This datasets covers features from various cat...  \n",
       "2   This datasets covers features from various cat...  \n",
       "3   This datasets covers features from various cat...  \n",
       "4   Check the movement of the financial market thr...  \n",
       "..                                                ...  \n",
       "90  **Author**: Confidential. Donated by Ross Quin...  \n",
       "91  More information about the data sets and the b...  \n",
       "92  3. Past Usage:\\n\\n4. Relevant Information\\nThe...  \n",
       "93  Context\\nThis dataset was created when I pract...  \n",
       "94  We scraped a large number of eBay auctions of ...  \n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "results = create_result_dataframe(query, qa)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This datasets covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentione',\n",
       "       'This datasets covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentione',\n",
       "       'This datasets covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentione',\n",
       "       'This datasets covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentione',\n",
       "       'Check the movement of the financial market through this dataset\\nUse your creativity and external information',\n",
       "       \"This dataset contains Apple's (AAPL) stock data for the last 10 years (from 2010 to date). I believe insights from this data can be used to build useful price forecasting algorithms to aid investment. I would like to thank Nasdaq for providing access to this rich dataset. I will make sure I update t\",\n",
       "       'analysis of stocks',\n",
       "       'It covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentioned in the pa',\n",
       "       'Context\\nInformation about more than 4600 companies tradable on Robinhood website\\nSource\\nThe information is scraped from Robinhood website\\nInspiration\\nThe dataset contains useful information about Public Companies are being traded in US Stock market. Information about company size, market cap, PE rat',\n",
       "       'Context\\nThe Stock Market forecasting and Modelling has always been the problem most researched by analysts, here we will present a dataset of the Indian Stock Exchange - Nifty50 Index . for use for modelling and forecasting ability by machine learning .\\nContent\\nThe Data consists of 9 Rows, directly ',\n",
       "       'Description:\\nThis dataset contains information about the products, stock levels, prices, and locations of sales.\\n\\nColumns description:\\n- Product: the name of the products sold.\\n- Stock: the quantity of each product in stock.\\n- Price: the price of each product.\\n- Place: the location where the product',\n",
       "       \"nasdaq_yes_changeP: Yesterday NASDAQ 100 change\\nnasdaq_lastweek_changeP: Last Week NASDAQ 100 change\\ntoday_changeP: Today Amazon's stock price change\\nTo learn more about the dataset and see a very simple prediction model applied to the dataset you may watch this YouTube Video where I have explained \",\n",
       "       'Data for an stock long position',\n",
       "       'Use case:\\nThis dataset can be valuable for retailers, supply chain managers, and market analysts. Retailers can use the information on stock levels and prices to make strategic pricing and stocking decisions. Supply chain managers can optimize inventory levels based on product popularity and locatio',\n",
       "       'Context\\nThis Data is gathered from NSE website  for the past three months I am posting this here so people can analyse this data \\n and gather meaningful insights from this.\\nExample -  Probability of Stock ending up at Max Pain with the help of Open Interest.\\nContent\\nThe dataset contains stock symbol',\n",
       "       'Use Case:\\nThis dataset is invaluable for researchers and analysts focusing on labor market trends, HR professionals seeking comparative analysis for salary benchmarking or recruiting strategies, and job seekers looking to understand the dynamics of the job market. It can also be used to develop mach',\n",
       "       'This dataset contains information about used motorcycles\\nThis data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.\\nThe columns in the given dataset are as follows:\\n\\nname\\nselling price\\nyear\\nseller type\\nowner\\nkm driven\\nex showro',\n",
       "       'Context\\nThe stock prices dataset of  a ticker is a good start to slice and dice and good for forecasting of the stock prices.\\nThe GOOG ticker data is taken\\nContent\\nDataset is comprising of the below columns and each row having the days data, an year data is pulled into csv file.\\nDate   Open    High ',\n",
       "       \"Content\\nThis is a dataset I started building for my future personal projects, as I think this kind of data is quite hard to acquire for free and in short time. I started acquiring data on March 21st, 2020 and intend to keep doing that constantly.\\nWhat you'll have inside this are news extracted from \",\n",
       "       'Further information can be retrieved from the [FICO website](https://community.fico.com/s/explainable-machine-learning-challenge).\\n\\n**Notes**\\n* We have obtained the dataset from [Kaggle](https://www.kaggle.com/datasets/averkiyoliabev/home-equity-line-of-creditheloc)\\n* This is a cleaned version of th',\n",
       "       '**Dataset description**',\n",
       "       'Context\\nThis Dataset contains the value of the Bitcoin stock from 14th September 2014 till Date \\nContent\\nIt is a very simple dataset to both explore and understand the columns are themselves descriptive in nature\\nAcknowledgements\\nSOURCE:\\nhttps://yahoofinance.com/ \\nInspiration\\nJust Explore the datase',\n",
       "       'A brief description of your dataset.',\n",
       "       'Context\\nTo build a AI to predict the stock price of the Dollar currency on IBOVESPA I had to make this dataset.\\nAll information collected here is from a standard graphic for stock prices.\\nContent\\nThe data is organized by prices and infos per minute.\\nEach row contains:\\ndate, open price, maximim value',\n",
       "       'Context\\nThis dataset is a playground for fundamental and technical analysis. This can serve as basic tutorial for time-series data analysis.\\nContent\\nDataset consists of following files:\\nLTFinanceHoldingsLtdStockPrice2017to2020.csv: The data related to LT Finance Holdings Ltd Stock Price from Feb 201',\n",
       "       'Data Set Information:',\n",
       "       'The Story\\nThis data set was part of my online course material for Data Analysis using Python over at Udemy.\\nThe Contents\\nThe dataset is very useful for beginners and novice number crunchers looking to run queries in a relatable and easy-to-understand dataset. It includes the data about shoppers of a',\n",
       "       'Content\\nThis dataset is a record of 7 common different fish species in fish market sales. With this dataset, a predictive model can be performed using machine friendly data and estimate the weight of fish can be predicted.\\n\\nAcknowledgements\\nThanks to all who make Kernels using this dataset and also ',\n",
       "       \"Context\\nThe data is of National Stock Exchange of India.\\nThe data is compiled to felicitate Machine Learning, without bothering much about Stock APIs.\\nContent\\nThe data is of National Stock Exchange of India's stock listings for each trading day of 2016 and 2017.\\nA brief description of columns.\\nSYMBO\",\n",
       "       \"If you reach this DATASET, please UPVOTE this dataset to show your appreciation\\nDATASET DETAILS:\\n  \\n1.Previous Close:        264.29,\\n2.Open:                265.58,\\n3.Bid:                266.06 x 800,\\n4.Ask:                266.06 x 900,\\n5.Day's Range:            265.31 - 266.27,\\n6.52 Week Range:     \",\n",
       "       'Use Case:\\nThis dataset is invaluable for chess enthusiasts, researchers, and developers interested in developing chess-related algorithms, studying patterns and trends in game outcomes and strategies, or creating predictive models on game results based on player ratings and opening moves. It can als',\n",
       "       \"Acknowledgements\\nWe wouldn't be here without the help of our web scraping and data mining experts at PromptCloud and DataStock. \\nInspiration\\nThe inspiration for this dataset came from Buzzfeed itself. We thought long and hard about the informative articles that we have on Buzzfeed. So we came up wit\",\n",
       "       'Use Case:\\nThis dataset can be instrumental for researchers and data scientists focusing on natural language processing (NLP), sentiment analysis, and trend spotting. It offers a rich resource for training machine learning models aimed at understanding public sentiment, detecting shifts in societal c',\n",
       "       'data from yahoo finance',\n",
       "       \"Context\\nThis is the dataset used in the second chapter of Aurlien Gron's recent book 'Hands-On Machine learning with Scikit-Learn and TensorFlow'. It serves as an excellent introduction to implementing machine learning algorithms because it requires rudimentary data cleaning, has an easily understan\",\n",
       "       'This Dataset is something I found online when I wanted to practice regression models. It is an openly available online dataset at multiple places. Though I do not know the exact origin and collection methodology of the data, I would recommend this dataset to everybody who is just beginning their jou',\n",
       "       '**Author**: Dr. Michael Brown\\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/dow+jones+index) - 2017\\n**Please cite**: [Paper](https://link.springer.com/content/pdf/10.1007%2F978-3-642-39712-7_3.pdf)  \\n\\n**Dow Jones Index Data Set**\\n\\nIn our research each record (row) is data for a week.  Ea',\n",
       "       'Context\\nThis dataset was created to make the project \"AI Learn to invest\" for SaturdaysAI - Euskadi 1st edition. The project can be found in https://github.com/ImanolR87/AI-Learn-to-invest\\nContent\\nMore than 400.000 random investments were created with the data from the last 10 years from the NYSE ma',\n",
       "       'The datasets talk about Stock Market,  in two Industry and each Industry has ten different companies with six columns and 600 rows  ,in the same date for all the 20 companies the period from \\n2020-02-06 to 2020-03-18 one month 30 day .\\nColumns means :\\nDate column : the perioid 2020-02-06 to 2020-03-',\n",
       "       '**Author**:   \\n**Source**: Unknown -   \\n**Please cite**:   \\n\\nThis is a dataset obtained from the StatLib repository. Here is the included description:\\n\\n The data provided are daily stock prices from January 1988 through October 1991, for ten aerospace companies.\\n\\n Source: collection of regression da',\n",
       "       'Context\\nHowdy folks! \\nI have prepared a starter dataset for time series practice. This is my 1st upload. Any questions/feedback are welcome. \\nContent\\n\\nThe data was prepared using Alpha Vantage API\\nThe data represents historical daily time series for a digital currency (BTC) traded on the Saudi marke',\n",
       "       'I will be updating this dataset for attributes that might reveal some more information about this dataset.\\nThanks for stopping by.\\nPeace.',\n",
       "       'Context\\nThis is historical data on cryptocurrency tradings for the period from 2016-01-01 to 2021-02-21.\\nIf you enjoy this dataset please upvote so I can see it is popular and I need to update it.\\nThank you!\\nContent\\nThis dataset will be good for data analysis in predicting the price for digital cryp',\n",
       "       'Content\\nThe dataset consists of ETH prices from March-2016 to the current date(1813 days) and the dataset will be updated on a weekly basis. \\nInformation regarding the data\\nThe data totally consists of 1813 records(1813 days) with 7 columns. The description of the features is given below\\n\\n\\n\\nNo\\nColum',\n",
       "       '### Acknowledgements\\nThis dataset is a compilation of multiple datasets found on Inside Airbnb.\\n\\n### Inspiration\\n* Can we predict the price of each house in different regions? \\n* Can we describe a region using the names of listings in that region? \\n* What can we learn about different regions from th',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'dataset for feature extraction',\n",
       "       'Uber vs Lyft\\nThis is a very beginner-friendly dataset. It does contain a lot of NA values. It is a good dataset if you want to use a Linear Regression Model to see the pattern between different predectors such as hour and price.\\nA really amazing part of this dataset is that I have included the corre',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'Acknowledgements\\nThis dataset was possible thanks to financialmodelingprep and opendatasoft - the sources of the data. To see how the data was integrated and reshaped check here.\\nInspiration\\nIs it possible to forecast the rating an agency will give to a company based on its financials?',\n",
       "       'MY Dataset',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       '**Dataset information:**\\n\\nThe dataset is about bankruptcy prediction of Polish companies. The data was collected from Emerging Markets Information Service (EMIS, [Web Link]), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the ',\n",
       "       'Context\\nDaily price information for stocks, aggregated into one big file.  \\n\\nContent\\nData was pulled using an api and contains general price information for all stocks that are tradable.  Fields include volume of trades, open and close, as well as high and low prices for the day.  The data goes back',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'Dataset sales',\n",
       "       '**Dataset Name**: card_transdata.csv\\n\\n**Description**:\\nThis dataset captures transaction patterns and behaviors that could indicate potential fraud in card transactions. The data is composed of several features designed to reflect the transactional context such as geographical location, transaction ',\n",
       "       'dataset for bme',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'Dataset used in the tabular data benchmark https://github.com/LeoGrin/tabular-benchmark, transformed in the same way. This dataset belongs to the \"classification on numerical features\" benchmark.\\n        Original source: https://www.kaggle.com/datasets/averkiyoliabev/home-equity-line-of-creditheloc?',\n",
       "       'Context\\nThis Data set Contains the values of Stock of Amazon which dates between 15 July ,2019 to 15 July,2020\\n\\nContent\\nThe Data set contains 7 different columns that includes Date, The opening value of the stock, the closing value of stock, volume and a few other things necessary to make prediction',\n",
       "       'Context\\nThis dataset is created for the prediction of future New York Housing Price based on the past 17 years of record. \\nContent\\nPlease check the details under the column description.\\nAcknowledgements\\nNew York City Department of Finance Open Source Data.\\nIf there is any violation, I am willing to ',\n",
       "       \"Acknowledgements\\nThis Dataset collected from Yahoo finance website\\n\\nInspiration\\nHow a sudden increasi in the volume affect stock trading? \\nWhat the impact of the variance between the adjusted close and the next day's opening price?\",\n",
       "       'Context\\nFacebook is a company that literally every kid is aware of. Its a household name. People from various age groups are there on this social media website. It has helped many in connecting with different people and also has helped some of the investors by earning them a good amount of money. Th',\n",
       "       '### Data Set Information\\n\\nThis is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a \\nsubset of 9 categories cataloged in a table called National Classification of Economic Activities (Classificação Nacional de \\nAtividade Econômicas - CN',\n",
       "       'Small dataset with time series of RAM prices over the years.',\n",
       "       'Context\\nThis Data set Contains the values of Stock of Amazon which dates between 1st October,2019 to 14 July,2020\\nContent\\nThe Data set contains 7 different columns that includes Date, The opening value of the stock, the closing value of stock, volume and a few other things necessary to make predicti',\n",
       "       'send jse/v1n1/datasets.lock\\n\\nto the address archive@jse.stat.ncsu.edu\\n\\nPEDAGOGICAL NOTES:\\nThis is a multi-purpose dataset that can be used at many points in an\\nintroductory course.  It includes many good numeric variables and\\nseveral options for dividing the cars up into groups.  Students tend to\\nbe',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'Domain dataset',\n",
       "       'Context\\nThe dataset is from a rental price prediction project I did. Includes different types of properties (Apartments, Independent floors, Independent houses, Villas etc.)\\nIt contains 12000 rental listings from a popular real estate website. It can be used for rental prediction projects, analysis ',\n",
       "       'Context\\nThe BSE SENSEX (also known as the SP Bombay Stock Exchange Sensitive Index or simply the SENSEX) is a free-float market-weighted stock market index of 30 well-established and financially sound companies listed on Bombay Stock Exchange. The 30 constituent companies which are some of the large',\n",
       "       \"Context\\nNetflix is one of the Biggest companies that is present in today's time. It comes under the popular FAANG companies and a dream company for many. Everyone  loves watch to watch movies and TV-Series on Netflix but the subscription prices are a little too much in my opinion. So why not invest \",\n",
       "       \"Acknowledgements\\nWe wouldn't be here without the help of our in house web scraping and data mining teams at PromptCloud and DataStock.\\nInspiration\\nThis dataset was created keeping in mind our data scientists and researchers across the world.\",\n",
       "       'Content\\nThis dataset contains meta data of around 60 Data Science YouTube channel videos meta data.\\nAcknowledgements\\nData scraped from https://wiki.digitalmethods.net/Dmi/ToolDatabase .\\nCover Photo: Photo by Rachit Tank on Unsplash.\\nMotivation :  Dataset by Gabriel Preda\\nInspiration\\nPossible uses fo',\n",
       "       \"Context\\nThere's a story behind every dataset and here's your opportunity to share yours.\\nContent\\nWhat's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.\\nAcknowledgements\\nWe wouldn't be h\",\n",
       "       'Context\\nProjects are a great way to learn data science. So I started my own. The numerous housing data sets on Kaggle were the inspiration for this data set. Predicting housing prices is a simple yet insightful regression problem. Understanding data takes time, and the more people analyze it, the fa',\n",
       "       '**Author**:   \\n**Source**: Unknown - Date unknown  \\n**Please cite**:   \\n\\nThis S dump contains 22 data sets from the\\nbook Visualizing Data published by\\nHobart Press (books@hobart.com).\\nThe dump was created by data.dump()\\nand can be read back into S by data.restore().\\nThe name of each S data set is th',\n",
       "       'Context\\nThis dataset was a part of the assignment of my coursework.\\nContent\\nThe dataset contains 90+ columns describing different aspects of all countries like GDP, Population, Electricity-consumption and many more. Most of the fields are explained here (others are standard terms you can search for)',\n",
       "       \"Context\\nI found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.\\nContent\\nThis dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a desc\",\n",
       "       'contains all historical daily prices open, high, low, close for all cryptocurrencies listed on CoinMarketCap.AcknowledgementsEvery Cryptocurrency Daily Market Price  I initially developed kernels for this dataset before making my own scraper and dataset so that I could keep it regularly updated.Coin',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'Context\\nThis is a dataset i generated during a hackathon for project purpose. Here i have scrapped data from Coursera official web site.  Our project aims to help any new learner get the right course to learn by just answering a few questions. It is an intelligent course recommendation system. Hence',\n",
       "       'Test dataset',\n",
       "       'The goal is to predict the sale price.\\n\\n**Attribute description**\\n\\nThe dataset contains the following columns:\\n\\n  * PARCELNO: unique identifier for each property. About 1% appear multiple times.\\n  * SALE_PRC: sale price ($)\\n  * LND_SQFOOT: land area (square feet)\\n  * TOTLVGAREA: floor area (square f',\n",
       "       'About Dataset\\nThis data set includes15K Fifa20 Players with 15+ features and their images , including their position, age, and Country, and many more. It can be used for learning Statistics, Performing Data Analysis, and Data Visualization using various libraries like Seaborn, Pandas-Bokeh, and Plot',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       '**Author**: Confidential. Donated by Ross Quinlan  \\n**Source**: [LibSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html), [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Australian+Credit+Approval)) - 1987    \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation',\n",
       "       'More information about the data sets and the book can be\\nobtained via gopher at the address\\nswis.stern.nyu.edu\\n\\nThe information is filed under\\n---> Academic Departments & Research Centers\\n---> Statistics and Operations Research\\n---> Publications\\n---> A Casebook for a First Course in Statistics and D',\n",
       "       '3. Past Usage:\\n\\n4. Relevant Information\\nThe ERA data set was originally gathered during an academic decision-making\\nexperiment aiming at determining which are the most important qualities of\\ncandidates for a certain type of jobs. Unlike the ESL data set (enclosed)\\nwhich was collected from expert rec',\n",
       "       \"Context\\nThis dataset was created when I practiced webscraping.\\nContent\\nThe data is a compilation of information on dogs who were available for adoption on December 12, 2019 in the Hungarian Database of Homeless Pets. In total, there were 2,937 dogs in the database. It contains information on dogs' n\",\n",
       "       'We scraped a large number of eBay auctions of a popular product. After preprocessing the auction data, we build the SB dataset. The goal is to share the labelled SB dataset with the researchers.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['short_description'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
